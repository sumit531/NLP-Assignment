{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391d1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f78759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataNeuron_Text_Similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8732147e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player burn-out worries robinson england coach...   \n",
       "3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  \n",
       "3  redford s vision of sundance despite sporting ...  \n",
       "4  mauresmo opens with victory in la amelie maure...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655545c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db005ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
    "    return ' '.join(tokens)\n",
    "df['text1'] = df['text1'].apply(preprocess_text)\n",
    "df['text2'] = df['text2'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce6263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between 'text1' and 'text2'\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix_text1 = tfidf_vectorizer.fit_transform(df['text1']).toarray()\n",
    "tfidf_matrix_text2 = tfidf_vectorizer.transform(df['text2']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09108ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = [cosine_similarity([tfidf_matrix_text1[i]], [tfidf_matrix_text2[i]])[0, 0] for i in range(len(df))]\n",
    "df['similarity'] = cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae86a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('text_data_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16663604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "df = pd.read_csv('text_data_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e521a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "      <td>0.202035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "      <td>0.070757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player worries robinson england coach andy rob...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "      <td>0.092618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak cotonsport hearts of oak set up ...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "      <td>0.136538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "      <td>0.107313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player worries robinson england coach andy rob...   \n",
       "3  hearts of oak cotonsport hearts of oak set up ...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  similarity  \n",
       "0  gardener wins double in glasgow britain s jaso...    0.202035  \n",
       "1  amnesty chief laments war failure the lack of ...    0.070757  \n",
       "2  hanks greeted at wintry premiere hollywood sta...    0.092618  \n",
       "3  redford s vision of sundance despite sporting ...    0.136538  \n",
       "4  mauresmo opens with victory in la amelie maure...    0.107313  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9548548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable (similarity scores)\n",
    "y = df['similarity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651e717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[['similarity']], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991a5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "input_layer = Input(shape=(1,))\n",
    "dense1 = Dense(128, activation='relu')(input_layer)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41cb515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 1.5837e-05 - mse: 1.5837e-05 - val_loss: 7.1450e-06 - val_mse: 7.1450e-06\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 817us/step - loss: 1.4781e-05 - mse: 1.4781e-05 - val_loss: 7.5186e-06 - val_mse: 7.5186e-06\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 787us/step - loss: 1.3692e-05 - mse: 1.3692e-05 - val_loss: 7.4259e-06 - val_mse: 7.4259e-06\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 1.2683e-05 - mse: 1.2683e-05 - val_loss: 5.6867e-06 - val_mse: 5.6867e-06\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 797us/step - loss: 1.1781e-05 - mse: 1.1781e-05 - val_loss: 5.4150e-06 - val_mse: 5.4150e-06\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 812us/step - loss: 1.1041e-05 - mse: 1.1041e-05 - val_loss: 5.8242e-06 - val_mse: 5.8242e-06\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 817us/step - loss: 1.0493e-05 - mse: 1.0493e-05 - val_loss: 5.2550e-06 - val_mse: 5.2550e-06\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 807us/step - loss: 9.8725e-06 - mse: 9.8725e-06 - val_loss: 4.2978e-06 - val_mse: 4.2978e-06\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 786us/step - loss: 9.6449e-06 - mse: 9.6449e-06 - val_loss: 4.2551e-06 - val_mse: 4.2551e-06\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 9.3181e-06 - mse: 9.3181e-06 - val_loss: 4.0631e-06 - val_mse: 4.0631e-06\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 836us/step - loss: 8.8459e-06 - mse: 8.8459e-06 - val_loss: 7.3682e-06 - val_mse: 7.3682e-06\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 837us/step - loss: 8.2908e-06 - mse: 8.2908e-06 - val_loss: 4.6551e-06 - val_mse: 4.6551e-06\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 818us/step - loss: 8.0966e-06 - mse: 8.0966e-06 - val_loss: 5.3073e-06 - val_mse: 5.3073e-06\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 824us/step - loss: 8.3038e-06 - mse: 8.3038e-06 - val_loss: 3.3347e-06 - val_mse: 3.3347e-06\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 817us/step - loss: 7.3536e-06 - mse: 7.3536e-06 - val_loss: 3.4308e-06 - val_mse: 3.4308e-06\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 819us/step - loss: 7.7022e-06 - mse: 7.7022e-06 - val_loss: 4.0412e-06 - val_mse: 4.0412e-06\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 7.4732e-06 - mse: 7.4732e-06 - val_loss: 3.0879e-06 - val_mse: 3.0879e-06\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 819us/step - loss: 6.9567e-06 - mse: 6.9567e-06 - val_loss: 2.9021e-06 - val_mse: 2.9021e-06\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 804us/step - loss: 6.6344e-06 - mse: 6.6344e-06 - val_loss: 3.4742e-06 - val_mse: 3.4742e-06\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 810us/step - loss: 6.6367e-06 - mse: 6.6367e-06 - val_loss: 3.4539e-06 - val_mse: 3.4539e-06\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 6.5239e-06 - mse: 6.5239e-06 - val_loss: 2.5802e-06 - val_mse: 2.5802e-06\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 809us/step - loss: 6.3218e-06 - mse: 6.3218e-06 - val_loss: 2.8003e-06 - val_mse: 2.8003e-06\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 823us/step - loss: 6.4838e-06 - mse: 6.4838e-06 - val_loss: 3.0066e-06 - val_mse: 3.0066e-06\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 818us/step - loss: 6.0968e-06 - mse: 6.0968e-06 - val_loss: 2.7046e-06 - val_mse: 2.7046e-06\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 846us/step - loss: 6.0708e-06 - mse: 6.0708e-06 - val_loss: 2.8955e-06 - val_mse: 2.8955e-06\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 803us/step - loss: 5.8500e-06 - mse: 5.8500e-06 - val_loss: 3.0471e-06 - val_mse: 3.0471e-06\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 792us/step - loss: 5.6426e-06 - mse: 5.6426e-06 - val_loss: 3.5578e-06 - val_mse: 3.5578e-06\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 831us/step - loss: 5.6705e-06 - mse: 5.6705e-06 - val_loss: 3.2720e-06 - val_mse: 3.2720e-06\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 5.6116e-06 - mse: 5.6116e-06 - val_loss: 1.9539e-06 - val_mse: 1.9539e-06\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 821us/step - loss: 5.5320e-06 - mse: 5.5320e-06 - val_loss: 2.3139e-06 - val_mse: 2.3139e-06\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 830us/step - loss: 6.1512e-06 - mse: 6.1512e-06 - val_loss: 2.7619e-06 - val_mse: 2.7619e-06\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 822us/step - loss: 5.5045e-06 - mse: 5.5045e-06 - val_loss: 1.8315e-06 - val_mse: 1.8315e-06\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 848us/step - loss: 5.3864e-06 - mse: 5.3864e-06 - val_loss: 1.6462e-06 - val_mse: 1.6462e-06\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 831us/step - loss: 5.3038e-06 - mse: 5.3038e-06 - val_loss: 1.8447e-06 - val_mse: 1.8447e-06\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 869us/step - loss: 4.7641e-06 - mse: 4.7641e-06 - val_loss: 1.6225e-06 - val_mse: 1.6225e-06\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 872us/step - loss: 4.7817e-06 - mse: 4.7817e-06 - val_loss: 1.5730e-06 - val_mse: 1.5730e-06\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 870us/step - loss: 4.9029e-06 - mse: 4.9029e-06 - val_loss: 5.8973e-06 - val_mse: 5.8973e-06\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 849us/step - loss: 5.0069e-06 - mse: 5.0069e-06 - val_loss: 1.8791e-06 - val_mse: 1.8791e-06\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 840us/step - loss: 5.3220e-06 - mse: 5.3220e-06 - val_loss: 1.4679e-06 - val_mse: 1.4679e-06\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 810us/step - loss: 4.4643e-06 - mse: 4.4643e-06 - val_loss: 1.8175e-06 - val_mse: 1.8175e-06\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 811us/step - loss: 4.3210e-06 - mse: 4.3210e-06 - val_loss: 1.5330e-06 - val_mse: 1.5330e-06\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 802us/step - loss: 4.2483e-06 - mse: 4.2483e-06 - val_loss: 2.1821e-06 - val_mse: 2.1821e-06\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 812us/step - loss: 4.1286e-06 - mse: 4.1286e-06 - val_loss: 2.4358e-06 - val_mse: 2.4358e-06\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 811us/step - loss: 3.6637e-06 - mse: 3.6637e-06 - val_loss: 1.6330e-06 - val_mse: 1.6330e-06\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 803us/step - loss: 3.6300e-06 - mse: 3.6300e-06 - val_loss: 1.3077e-06 - val_mse: 1.3077e-06\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 801us/step - loss: 3.8658e-06 - mse: 3.8658e-06 - val_loss: 1.5118e-06 - val_mse: 1.5118e-06\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 831us/step - loss: 3.5401e-06 - mse: 3.5401e-06 - val_loss: 1.0502e-06 - val_mse: 1.0502e-06\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 795us/step - loss: 3.2817e-06 - mse: 3.2817e-06 - val_loss: 1.0514e-06 - val_mse: 1.0514e-06\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 812us/step - loss: 3.3810e-06 - mse: 3.3810e-06 - val_loss: 1.1250e-06 - val_mse: 1.1250e-06\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 795us/step - loss: 3.2531e-06 - mse: 3.2531e-06 - val_loss: 1.0991e-06 - val_mse: 1.0991e-06\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 793us/step - loss: 2.9610e-06 - mse: 2.9610e-06 - val_loss: 1.5135e-06 - val_mse: 1.5135e-06\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 3.1250e-06 - mse: 3.1250e-06 - val_loss: 1.5416e-06 - val_mse: 1.5416e-06\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 763us/step - loss: 2.8807e-06 - mse: 2.8807e-06 - val_loss: 7.9696e-07 - val_mse: 7.9696e-07\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 2.6472e-06 - mse: 2.6472e-06 - val_loss: 9.3450e-07 - val_mse: 9.3450e-07\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 796us/step - loss: 2.9841e-06 - mse: 2.9841e-06 - val_loss: 1.5058e-06 - val_mse: 1.5058e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 2.9930e-06 - mse: 2.9930e-06 - val_loss: 7.4999e-07 - val_mse: 7.4999e-07\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 2.2022e-06 - mse: 2.2022e-06 - val_loss: 1.2105e-06 - val_mse: 1.2105e-06\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 782us/step - loss: 2.3397e-06 - mse: 2.3397e-06 - val_loss: 1.7664e-06 - val_mse: 1.7664e-06\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 798us/step - loss: 2.8965e-06 - mse: 2.8965e-06 - val_loss: 7.7411e-07 - val_mse: 7.7411e-07\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 796us/step - loss: 2.2268e-06 - mse: 2.2268e-06 - val_loss: 6.3904e-07 - val_mse: 6.3904e-07\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 805us/step - loss: 2.0076e-06 - mse: 2.0076e-06 - val_loss: 8.2040e-07 - val_mse: 8.2040e-07\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 805us/step - loss: 2.0001e-06 - mse: 2.0001e-06 - val_loss: 6.7770e-07 - val_mse: 6.7770e-07\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 1.8561e-06 - mse: 1.8561e-06 - val_loss: 1.0714e-06 - val_mse: 1.0714e-06\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 1.8158e-06 - mse: 1.8158e-06 - val_loss: 8.7533e-07 - val_mse: 8.7533e-07\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 841us/step - loss: 2.1441e-06 - mse: 2.1441e-06 - val_loss: 5.5320e-07 - val_mse: 5.5320e-07\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 800us/step - loss: 1.6778e-06 - mse: 1.6778e-06 - val_loss: 7.9671e-07 - val_mse: 7.9671e-07\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 804us/step - loss: 2.1065e-06 - mse: 2.1065e-06 - val_loss: 9.5262e-07 - val_mse: 9.5262e-07\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 1.7502e-06 - mse: 1.7502e-06 - val_loss: 2.0891e-06 - val_mse: 2.0891e-06\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 802us/step - loss: 1.7793e-06 - mse: 1.7793e-06 - val_loss: 5.6780e-07 - val_mse: 5.6780e-07\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 788us/step - loss: 1.6770e-06 - mse: 1.6770e-06 - val_loss: 4.5910e-07 - val_mse: 4.5910e-07\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 790us/step - loss: 2.5117e-06 - mse: 2.5117e-06 - val_loss: 1.1776e-06 - val_mse: 1.1776e-06\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 799us/step - loss: 1.4502e-06 - mse: 1.4502e-06 - val_loss: 4.3939e-07 - val_mse: 4.3939e-07\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 785us/step - loss: 1.2693e-06 - mse: 1.2693e-06 - val_loss: 1.0930e-06 - val_mse: 1.0930e-06\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 763us/step - loss: 1.5257e-06 - mse: 1.5257e-06 - val_loss: 4.1414e-07 - val_mse: 4.1414e-07\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 1.6476e-06 - mse: 1.6476e-06 - val_loss: 8.8504e-07 - val_mse: 8.8504e-07\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 773us/step - loss: 1.2380e-06 - mse: 1.2380e-06 - val_loss: 3.5455e-07 - val_mse: 3.5455e-07\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 1.5524e-06 - mse: 1.5524e-06 - val_loss: 4.3074e-07 - val_mse: 4.3074e-07\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 787us/step - loss: 1.0914e-06 - mse: 1.0914e-06 - val_loss: 4.4660e-07 - val_mse: 4.4660e-07\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 1.4481e-06 - mse: 1.4481e-06 - val_loss: 3.2256e-07 - val_mse: 3.2256e-07\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 1.0541e-06 - mse: 1.0541e-06 - val_loss: 5.1853e-07 - val_mse: 5.1853e-07\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 777us/step - loss: 9.9859e-07 - mse: 9.9859e-07 - val_loss: 4.1071e-07 - val_mse: 4.1071e-07\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 848us/step - loss: 9.3489e-07 - mse: 9.3489e-07 - val_loss: 2.9814e-07 - val_mse: 2.9814e-07\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 785us/step - loss: 1.1791e-06 - mse: 1.1791e-06 - val_loss: 2.9548e-07 - val_mse: 2.9548e-07\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 1.1491e-06 - mse: 1.1491e-06 - val_loss: 3.6768e-07 - val_mse: 3.6768e-07\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 778us/step - loss: 1.0643e-06 - mse: 1.0643e-06 - val_loss: 4.5462e-07 - val_mse: 4.5462e-07\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 8.2942e-07 - mse: 8.2942e-07 - val_loss: 3.4415e-07 - val_mse: 3.4415e-07\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 768us/step - loss: 1.2986e-06 - mse: 1.2986e-06 - val_loss: 1.2507e-06 - val_mse: 1.2507e-06\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 771us/step - loss: 8.8683e-07 - mse: 8.8683e-07 - val_loss: 2.7701e-07 - val_mse: 2.7701e-07\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 7.9524e-07 - mse: 7.9524e-07 - val_loss: 2.8870e-07 - val_mse: 2.8870e-07\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 7.3034e-07 - mse: 7.3034e-07 - val_loss: 2.5851e-07 - val_mse: 2.5851e-07\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 8.3114e-07 - mse: 8.3114e-07 - val_loss: 2.5229e-07 - val_mse: 2.5229e-07\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 796us/step - loss: 7.2799e-07 - mse: 7.2799e-07 - val_loss: 7.7952e-07 - val_mse: 7.7952e-07\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 790us/step - loss: 6.4883e-07 - mse: 6.4883e-07 - val_loss: 2.7143e-07 - val_mse: 2.7143e-07\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 1.0198e-06 - mse: 1.0198e-06 - val_loss: 1.7362e-06 - val_mse: 1.7362e-06\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 780us/step - loss: 7.7217e-07 - mse: 7.7217e-07 - val_loss: 7.7269e-07 - val_mse: 7.7269e-07\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 789us/step - loss: 9.6013e-07 - mse: 9.6013e-07 - val_loss: 3.9546e-07 - val_mse: 3.9546e-07\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 4.9654e-07 - mse: 4.9654e-07 - val_loss: 2.3507e-07 - val_mse: 2.3507e-07\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 777us/step - loss: 6.6855e-07 - mse: 6.6855e-07 - val_loss: 2.8787e-07 - val_mse: 2.8787e-07\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 785us/step - loss: 6.8440e-07 - mse: 6.8440e-07 - val_loss: 3.1437e-07 - val_mse: 3.1437e-07\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 7.2078e-07 - mse: 7.2078e-07 - val_loss: 1.7004e-06 - val_mse: 1.7004e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad26d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training History:\n",
      "{'loss': [1.5837484170333482e-05, 1.4780970559513662e-05, 1.369173787679756e-05, 1.2682576198130846e-05, 1.1781397006416228e-05, 1.1040715435228776e-05, 1.0492757610336412e-05, 9.872534974419978e-06, 9.644932106311899e-06, 9.318116099166218e-06, 8.845874617691152e-06, 8.290799996757414e-06, 8.096566489257384e-06, 8.303828508360311e-06, 7.353587989200605e-06, 7.702246875851415e-06, 7.473220193787711e-06, 6.956658126000548e-06, 6.634388228121679e-06, 6.6367065301164985e-06, 6.523910087707918e-06, 6.321837190625956e-06, 6.483773631771328e-06, 6.096768174757017e-06, 6.070804374758154e-06, 5.850017259945162e-06, 5.64259926250088e-06, 5.670469363394659e-06, 5.611552296613809e-06, 5.5319837883871514e-06, 6.151222351036267e-06, 5.504506134457188e-06, 5.386375505622709e-06, 5.303771104081534e-06, 4.7641078708693385e-06, 4.781666120834416e-06, 4.902874024992343e-06, 5.00690157423378e-06, 5.321962817106396e-06, 4.46428111899877e-06, 4.321005235397024e-06, 4.2482911339902785e-06, 4.128577984374715e-06, 3.6637291032093344e-06, 3.630043465818744e-06, 3.865839516947744e-06, 3.540068519214401e-06, 3.281659473941545e-06, 3.381003580216202e-06, 3.253097247579717e-06, 2.961028258141596e-06, 3.1249837775249034e-06, 2.880745341826696e-06, 2.6472318950254703e-06, 2.984108277814812e-06, 2.993047701238538e-06, 2.202152245445177e-06, 2.3396630695060594e-06, 2.89653985419136e-06, 2.226834340035566e-06, 2.007569946727017e-06, 2.000125050471979e-06, 1.8561484012025176e-06, 1.8158149259761558e-06, 2.1440666841954226e-06, 1.6778478766354965e-06, 2.1065202417958062e-06, 1.7502370610600337e-06, 1.7793350934880436e-06, 1.6770277397881728e-06, 2.5116523829638027e-06, 1.4501862324323156e-06, 1.2693068356384174e-06, 1.525694528936583e-06, 1.6476246855745558e-06, 1.2379661029626732e-06, 1.5524165064562112e-06, 1.0914128552030888e-06, 1.4481269090538262e-06, 1.0540576340645202e-06, 9.98593804979464e-07, 9.348909202344657e-07, 1.179085757030407e-06, 1.1490926681290148e-06, 1.0643207133398391e-06, 8.29423868253798e-07, 1.2986162118977518e-06, 8.868312306731241e-07, 7.95237838246976e-07, 7.303371489797428e-07, 8.3113826576664e-07, 7.279902547452366e-07, 6.488266990345437e-07, 1.0198483550993842e-06, 7.721677661720605e-07, 9.601294550520834e-07, 4.965427251590881e-07, 6.685455673505203e-07, 6.84401925354905e-07, 7.207789280982979e-07], 'mse': [1.5837484170333482e-05, 1.4780970559513662e-05, 1.369173787679756e-05, 1.2682576198130846e-05, 1.1781397006416228e-05, 1.1040715435228776e-05, 1.0492757610336412e-05, 9.872534974419978e-06, 9.644932106311899e-06, 9.318116099166218e-06, 8.845874617691152e-06, 8.290799996757414e-06, 8.096566489257384e-06, 8.303828508360311e-06, 7.353587989200605e-06, 7.702246875851415e-06, 7.473220193787711e-06, 6.956658126000548e-06, 6.634388228121679e-06, 6.6367065301164985e-06, 6.523910087707918e-06, 6.321837190625956e-06, 6.483773631771328e-06, 6.096768174757017e-06, 6.070804374758154e-06, 5.850017259945162e-06, 5.64259926250088e-06, 5.670469363394659e-06, 5.611552296613809e-06, 5.5319837883871514e-06, 6.151222351036267e-06, 5.504506134457188e-06, 5.386375505622709e-06, 5.303771104081534e-06, 4.7641078708693385e-06, 4.781666120834416e-06, 4.902874024992343e-06, 5.00690157423378e-06, 5.321962817106396e-06, 4.46428111899877e-06, 4.321005235397024e-06, 4.2482911339902785e-06, 4.128577984374715e-06, 3.6637291032093344e-06, 3.630043465818744e-06, 3.865839516947744e-06, 3.540068519214401e-06, 3.281659473941545e-06, 3.381003580216202e-06, 3.253097247579717e-06, 2.961028258141596e-06, 3.1249837775249034e-06, 2.880745341826696e-06, 2.6472318950254703e-06, 2.984108277814812e-06, 2.993047701238538e-06, 2.202152245445177e-06, 2.3396630695060594e-06, 2.89653985419136e-06, 2.226834340035566e-06, 2.007569946727017e-06, 2.000125050471979e-06, 1.8561484012025176e-06, 1.8158149259761558e-06, 2.1440666841954226e-06, 1.6778478766354965e-06, 2.1065202417958062e-06, 1.7502370610600337e-06, 1.7793350934880436e-06, 1.6770277397881728e-06, 2.5116523829638027e-06, 1.4501862324323156e-06, 1.2693068356384174e-06, 1.525694528936583e-06, 1.6476246855745558e-06, 1.2379661029626732e-06, 1.5524165064562112e-06, 1.0914128552030888e-06, 1.4481269090538262e-06, 1.0540576340645202e-06, 9.98593804979464e-07, 9.348909202344657e-07, 1.179085757030407e-06, 1.1490926681290148e-06, 1.0643207133398391e-06, 8.29423868253798e-07, 1.2986162118977518e-06, 8.868312306731241e-07, 7.95237838246976e-07, 7.303371489797428e-07, 8.3113826576664e-07, 7.279902547452366e-07, 6.488266990345437e-07, 1.0198483550993842e-06, 7.721677661720605e-07, 9.601294550520834e-07, 4.965427251590881e-07, 6.685455673505203e-07, 6.84401925354905e-07, 7.207789280982979e-07], 'val_loss': [7.14495763531886e-06, 7.518556230934337e-06, 7.425933290505782e-06, 5.686655185854761e-06, 5.4150364121596795e-06, 5.8241516853740904e-06, 5.2550358304870315e-06, 4.2977890188922174e-06, 4.255122348695295e-06, 4.063132564624539e-06, 7.36818492441671e-06, 4.6550776460208e-06, 5.307296760292957e-06, 3.334718485348276e-06, 3.4308193335164106e-06, 4.04124375563697e-06, 3.087946197410929e-06, 2.9020707188465167e-06, 3.4741567560558906e-06, 3.4538991258159513e-06, 2.5802287382248323e-06, 2.8003062197967665e-06, 3.0065591545280768e-06, 2.704631697270088e-06, 2.895519401135971e-06, 3.047142399736913e-06, 3.557793434083578e-06, 3.272047479185858e-06, 1.953933860932011e-06, 2.313861614311463e-06, 2.7619428237812826e-06, 1.83152360477834e-06, 1.6461831364722457e-06, 1.8447248066877364e-06, 1.622504669285263e-06, 1.5730413451819913e-06, 5.8972768783860374e-06, 1.879054707387695e-06, 1.4679336572953616e-06, 1.8174866909248522e-06, 1.5329500229199766e-06, 2.182081516366452e-06, 2.4357764232263435e-06, 1.6329931895597838e-06, 1.3077093399260775e-06, 1.5117748262127861e-06, 1.050249579748197e-06, 1.0514105497350101e-06, 1.124982986766554e-06, 1.0991202543664258e-06, 1.5134563682295266e-06, 1.5416414953506319e-06, 7.969638318172656e-07, 9.344996669824468e-07, 1.5057652262839838e-06, 7.499938305954856e-07, 1.2104783309041522e-06, 1.7664282268015086e-06, 7.74108173118293e-07, 6.390414455381688e-07, 8.204020787161426e-07, 6.777044063710491e-07, 1.071445808520366e-06, 8.753311817599752e-07, 5.53204472453217e-07, 7.967076953718788e-07, 9.526220878797176e-07, 2.0891079657303635e-06, 5.677991339325672e-07, 4.5910289259154524e-07, 1.1776398878282635e-06, 4.3939130023318285e-07, 1.0930273219855735e-06, 4.141396630075178e-07, 8.85039696640888e-07, 3.545468985066691e-07, 4.3073561073470046e-07, 4.466016605420009e-07, 3.225613625090773e-07, 5.185285658626526e-07, 4.107050131096912e-07, 2.9814091817570443e-07, 2.954845399472106e-07, 3.676795472529193e-07, 4.546211300748837e-07, 3.441491287503595e-07, 1.2507176734288805e-06, 2.770057960788108e-07, 2.8869717993984523e-07, 2.585148592970654e-07, 2.522858153497509e-07, 7.795177339176007e-07, 2.714349989219045e-07, 1.736220042403147e-06, 7.726881676717312e-07, 3.954625924507127e-07, 2.3507212176809844e-07, 2.878686302665301e-07, 3.143694016216614e-07, 1.700407437965623e-06], 'val_mse': [7.14495763531886e-06, 7.518556230934337e-06, 7.425933290505782e-06, 5.686655185854761e-06, 5.4150364121596795e-06, 5.8241516853740904e-06, 5.2550358304870315e-06, 4.2977890188922174e-06, 4.255122348695295e-06, 4.063132564624539e-06, 7.36818492441671e-06, 4.6550776460208e-06, 5.307296760292957e-06, 3.334718485348276e-06, 3.4308193335164106e-06, 4.04124375563697e-06, 3.087946197410929e-06, 2.9020707188465167e-06, 3.4741567560558906e-06, 3.4538991258159513e-06, 2.5802287382248323e-06, 2.8003062197967665e-06, 3.0065591545280768e-06, 2.704631697270088e-06, 2.895519401135971e-06, 3.047142399736913e-06, 3.557793434083578e-06, 3.272047479185858e-06, 1.953933860932011e-06, 2.313861614311463e-06, 2.7619428237812826e-06, 1.83152360477834e-06, 1.6461831364722457e-06, 1.8447248066877364e-06, 1.622504669285263e-06, 1.5730413451819913e-06, 5.8972768783860374e-06, 1.879054707387695e-06, 1.4679336572953616e-06, 1.8174866909248522e-06, 1.5329500229199766e-06, 2.182081516366452e-06, 2.4357764232263435e-06, 1.6329931895597838e-06, 1.3077093399260775e-06, 1.5117748262127861e-06, 1.050249579748197e-06, 1.0514105497350101e-06, 1.124982986766554e-06, 1.0991202543664258e-06, 1.5134563682295266e-06, 1.5416414953506319e-06, 7.969638318172656e-07, 9.344996669824468e-07, 1.5057652262839838e-06, 7.499938305954856e-07, 1.2104783309041522e-06, 1.7664282268015086e-06, 7.74108173118293e-07, 6.390414455381688e-07, 8.204020787161426e-07, 6.777044063710491e-07, 1.071445808520366e-06, 8.753311817599752e-07, 5.53204472453217e-07, 7.967076953718788e-07, 9.526220878797176e-07, 2.0891079657303635e-06, 5.677991339325672e-07, 4.5910289259154524e-07, 1.1776398878282635e-06, 4.3939130023318285e-07, 1.0930273219855735e-06, 4.141396630075178e-07, 8.85039696640888e-07, 3.545468985066691e-07, 4.3073561073470046e-07, 4.466016605420009e-07, 3.225613625090773e-07, 5.185285658626526e-07, 4.107050131096912e-07, 2.9814091817570443e-07, 2.954845399472106e-07, 3.676795472529193e-07, 4.546211300748837e-07, 3.441491287503595e-07, 1.2507176734288805e-06, 2.770057960788108e-07, 2.8869717993984523e-07, 2.585148592970654e-07, 2.522858153497509e-07, 7.795177339176007e-07, 2.714349989219045e-07, 1.736220042403147e-06, 7.726881676717312e-07, 3.954625924507127e-07, 2.3507212176809844e-07, 2.878686302665301e-07, 3.143694016216614e-07, 1.700407437965623e-06]}\n"
     ]
    }
   ],
   "source": [
    "# Display the training history\n",
    "print(\"Training History:\")\n",
    "print(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dec40ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 614us/step - loss: 1.7004e-06 - mse: 1.7004e-06\n",
      "Mean Squared Error on Validation Set: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "mse = model.evaluate(X_val, y_val)\n",
    "print(f'Mean Squared Error on Validation Set: {mse[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2294baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitsamanta/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('semantic_similarity_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb287e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
